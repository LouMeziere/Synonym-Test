Model name, vocabulary size, # of correct labels (C), # of questions answered without guessing (V), model accuracy (C/V) 
word2vec-google-news-300, 3000000, 70, 79, 0.8860759493670886
Model name, vocabulary size, # of correct labels (C), # of questions answered without guessing (V), model accuracy (C/V) 
word2vec-google-news-300, 3000000, 70, 79, 0.8860759493670886
Model name, vocabulary size, # of correct labels (C), # of questions answered without guessing (V), model accuracy (C/V) 
C1-C1, twitter-50, 1193514, 36, 78, 0.46153846153846156
Model name, vocabulary size, # of correct labels (C), # of questions answered without guessing (V), model accuracy (C/V) 
C2-E2, twitter-100, 1193514, 39, 78, 0.5
Model name, vocabulary size, # of correct labels (C), # of questions answered without guessing (V), model accuracy (C/V) 
C3-E3, crawl-subwords, 999999, 74, 80, 0.925
Model name, vocabulary size, # of correct labels (C), # of questions answered without guessing (V), model accuracy (C/V) 
C4-E4, wiki-giga, 400000, 71, 80, 0.8875
Model name, vocabulary size, # of correct labels (C), # of questions answered without guessing (V), model accuracy (C/V) 
E5-W1 model0.model, 21058, 14, 57, 0.24561403508771928
Model name, vocabulary size, # of correct labels (C), # of questions answered without guessing (V), model accuracy (C/V) 
E5-W2 model1.model, 21058, 20, 57, 0.3508771929824561
Model name, vocabulary size, # of correct labels (C), # of questions answered without guessing (V), model accuracy (C/V) 
E6-W1 model2.model, 21058, 13, 57, 0.22807017543859648
Model name, vocabulary size, # of correct labels (C), # of questions answered without guessing (V), model accuracy (C/V) 
E6-W2 model3.model, 21058, 14, 57, 0.24561403508771928
